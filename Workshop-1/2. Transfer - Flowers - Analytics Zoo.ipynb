{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createDefault\n",
      "creating: createSGD\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from bigdl.util.common import * \n",
    "from bigdl.transform.vision.image import *\n",
    "from bigdl.transform.vision import image\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import DoubleType, StringType\n",
    "from bigdl.nn.layer import *\n",
    "from bigdl.nn.criterion import *\n",
    "from pyspark import SparkConf\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "from zoo.common.nncontext import *\n",
    "from zoo.pipeline.nnframes.nn_classifier import *\n",
    "from zoo.pipeline.nnframes.nn_image_reader import *\n",
    "from zoo.pipeline.nnframes.nn_image_transformer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.17.0.2:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[2]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[2] appName=PySparkShell>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparkConf = SparkConf().setAppName(\"ImageTransferLearningExample\")\n",
    "sc = get_nncontext(sparkConf)\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createNNModel\n"
     ]
    }
   ],
   "source": [
    "model_path = '../../../model/bigdl_inception-v1_imagenet_0.4.0.model' \n",
    "preTrainedNNModel = NNModel(Model.loadModel(model_path), [3,224,224]).setPredictionCol(\"embedding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Flowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  218M  100  218M    0     0  69.9M      0  0:00:03  0:00:03 --:--:-- 69.9M\n"
     ]
    }
   ],
   "source": [
    "!curl -LO http://download.tensorflow.org/example_images/flower_photos.tgz\n",
    "!tar xzf flower_photos.tgz\n",
    "!rm flower_photos/LICENSE.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tulips\n",
      "roses\n",
      "('Duplicate file name', '15922772266_1167a06620.jpg')\n",
      "daisy\n",
      "sunflowers\n",
      "dandelion\n"
     ]
    }
   ],
   "source": [
    "def flowers():\n",
    "    classes = {}\n",
    "    file_name_set = set()\n",
    "    file_name_class = {}\n",
    "\n",
    "    image_path = 'flower_photos'\n",
    "    for dir_name in os.listdir(image_path):\n",
    "        if os.path.isdir(image_path + '/' + dir_name):\n",
    "            print(dir_name)\n",
    "            classes.setdefault(dir_name, float(len(classes) + 1))\n",
    "            for file_name in os.listdir(image_path + '/' + dir_name):\n",
    "                if file_name in file_name_set:\n",
    "                    print('Duplicate file name', file_name)\n",
    "                file_name_set.add(file_name)\n",
    "                file_name_class[file_name] = classes[dir_name]\n",
    "            \n",
    "    return classes, file_name_class\n",
    "\n",
    "classes, train_image_to_class = flowers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'daisy': 3.0,\n",
       " 'dandelion': 5.0,\n",
       " 'roses': 2.0,\n",
       " 'sunflowers': 4.0,\n",
       " 'tulips': 1.0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('partition number: ', 12)\n"
     ]
    }
   ],
   "source": [
    "data_path = 'flower_photos/*/*'\n",
    "image_path = data_path\n",
    "imageDF = NNImageReader.readImages(image_path, sc).repartition(12).cache()\n",
    "print (\"partition number: \", imageDF.rdd.getNumPartitions())\n",
    "print (\"image number: \", imageDF.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.listdir(data_path + '/train_img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create array of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getName = udf(lambda row: row[0].split('/')[-1])\n",
    "getLabel = udf(lambda name: train_image_to_class[name], DoubleType())\n",
    "labelDF = imageDF \\\n",
    "    .withColumn(\"name\", getName(col(\"image\"))) \\\n",
    "    .withColumn(\"label\", getLabel(col('name')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelDF.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingDF, validationDF) = labelDF.randomSplit([0.9, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingDF.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compose a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = NNImageTransformer(\n",
    "    image.Pipeline([Resize(256, 256), \n",
    "                    CenterCrop(224, 224), \n",
    "                    ChannelNormalize(123.0, 117.0, 104.0)])). \\\n",
    "        setInputCol(\"image\"). \\\n",
    "        setOutputCol(\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = transformer.transform(trainingDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingEmbedDF = preTrainedNNModel.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingEmbedDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load pretrained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bigdl.optim.optimizer import Optimizer, Adam, MaxEpoch, EveryEpoch, Top1Accuracy, \\\n",
    "    TrainSummary, ValidationSummary, SeveralIteration, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrModel = Sequential().add(Linear(1000, len(classes))).add(LogSoftMax())\n",
    "\n",
    "classifier = NNClassifier(lrModel, ClassNLLCriterion(), [1000]) \\\n",
    "        .setOptimMethod(SGD(nesterov=True, momentum=0.9, dampening=0.0)) \\\n",
    "        .setLearningRate(LEARNING_RATE) \\\n",
    "        .setBatchSize(BATCH_SIZE) \\\n",
    "        .setMaxEpoch(EPOCHS) \\\n",
    "        .setFeaturesCol(\"embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", \n",
    "    predictionCol=\"prediction\", \n",
    "    metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline = Pipeline(stages=[transformer, preTrainedNNModel, classifier])\n",
    "# pipeline = Pipeline(stages=[transformer, preTrainedNNModel, classifier])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grocery_model = classifier.fit(trainingEmbedDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainPredictDF = grocery_model.transform(trainingDF)\n",
    "# evaluator.evaluate(trainPredictDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validationEmbedDF = preTrainedNNModel.transform(transformer.transform(validationDF))\n",
    "predictionDF = grocery_model.transform(validationEmbedDF).cache()\n",
    "predictionDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.evaluate(predictionDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
