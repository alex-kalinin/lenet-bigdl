{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import DoubleType, StringType\n",
    "\n",
    "from bigdl.nn.criterion import CrossEntropyCriterion\n",
    "from zoo.common.nncontext import init_nncontext\n",
    "from zoo.feature.image import RowToImageFeature, ImageResize, ImageCenterCrop, ImageChannelNormalize, ImageMatToTensor, ImageFeatureToTensor\n",
    "\n",
    "from zoo.pipeline.api.keras.layers import Dense, Input, Flatten\n",
    "from zoo.pipeline.api.keras.models import Model\n",
    "from zoo.pipeline.api.net import Net\n",
    "from zoo.pipeline.nnframes import NNImageReader, ChainedPreprocessing, NNClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = init_nncontext(\"ImageTransferLearningExample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pretrained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget 'https://s3-ap-southeast-1.amazonaws.com/bigdl-models/imageclassification/imagenet/bigdl_inception-v1_imagenet_0.4.0.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget 'https://s3.amazonaws.com/elephantscale-public/bigdl/cat-dog.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -o cat-dog.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'bigdl_inception-v1_imagenet_0.4.0.model' \n",
    "full_model = Net.load_bigdl(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Flowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -LO http://download.tensorflow.org/example_images/flower_photos.tgz\n",
    "!tar xzf flower_photos.tgz\n",
    "!rm flower_photos/LICENSE.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls flower_photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls flower_photos/daisy | head -4\n",
    "!ls flower_photos/dandelion | head -4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Image.open('flower_photos/daisy/10140303196_b88d3d6cec.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Image.open('flower_photos/dandelion/10437652486_aa86c14985.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flowers():\n",
    "    classes = {}\n",
    "    file_name_set = set()\n",
    "    file_name_class = {}\n",
    "\n",
    "    image_path = 'flower_photos'\n",
    "    for dir_name in os.listdir(image_path):\n",
    "        if os.path.isdir(image_path + '/' + dir_name):\n",
    "            print(dir_name)\n",
    "            classes.setdefault(dir_name, float(len(classes) + 1))\n",
    "            for file_name in os.listdir(image_path + '/' + dir_name):\n",
    "                if file_name in file_name_set:\n",
    "                    print('Duplicate file name', file_name)\n",
    "                file_name_set.add(file_name)\n",
    "                file_name_class[file_name] = classes[dir_name]\n",
    "            \n",
    "    return classes, file_name_class\n",
    "\n",
    "classes, train_image_to_class = flowers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To consume less memory and shorted training, we'll only use a random subsample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf sampled/\n",
    "\n",
    "import os, shutil, subprocess\n",
    "\n",
    "for class_name in classes.keys():\n",
    "    sampled_train = 'sampled/train/'\n",
    "    sampled_test = 'sampled/test/'\n",
    "    if not os.path.exists(sampled_train + class_name):\n",
    "        os.makedirs(sampled_train + class_name)\n",
    "    if not os.path.exists(sampled_test + class_name):\n",
    "        os.makedirs(sampled_test + class_name)\n",
    "\n",
    "    subprocess.call([\"cp flower_photos/\" + class_name + \"/[56]*.jpg \" \n",
    "                     + sampled_train + class_name], shell=True)\n",
    "    subprocess.call([\"cp flower_photos/\" + class_name + \"/[78]*.jpg \" \n",
    "                     + sampled_test + class_name], shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -1 sampled/train/roses | wc -l\n",
    "!ls -1 sampled/train/daisy | wc -l\n",
    "!ls -1 sampled/train/sunflowers | wc -l\n",
    "!ls -1 sampled/train/dandelion | wc -l\n",
    "!ls -1 sampled/train/tulips | wc -l\n",
    "\n",
    "!ls -1 sampled/test/roses | wc -l\n",
    "!ls -1 sampled/test/daisy | wc -l\n",
    "!ls -1 sampled/test/sunflowers | wc -l\n",
    "!ls -1 sampled/test/dandelion | wc -l\n",
    "!ls -1 sampled/test/tulips | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingDF = NNImageReader.readImages('sampled/train/*/*', sc).repartition(32).cache()\n",
    "print (\"partition number: \", trainingDF.rdd.getNumPartitions())\n",
    "print (\"image number: \", trainingDF.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.listdir(data_path + '/train_img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingDF.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create array of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getName = udf(lambda row: row[0].split('/')[-1])\n",
    "getLabel = udf(lambda name: train_image_to_class[name], DoubleType())\n",
    "trainingDF = trainingDF \\\n",
    "    .withColumn(\"name\", getName(col(\"image\"))) \\\n",
    "    .withColumn(\"label\", getLabel(col('name'))).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingDF.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingDF.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (trainingDF, validationDF) = labelDF.randomSplit([0.9, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validationDF.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compose a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = ChainedPreprocessing(\n",
    "        [RowToImageFeature(), \n",
    "         ImageResize(256, 256), \n",
    "         ImageCenterCrop(224, 224),\n",
    "         ImageChannelNormalize(123.0, 117.0, 104.0), \n",
    "         ImageMatToTensor(), \n",
    "         ImageFeatureToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load pretrained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in full_model.layers:\n",
    "    print (layer.name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = full_model.new_graph([\"pool5/drop_7x7_s1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputNode = Input(name=\"input\", shape=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception = model.to_keras()(inputNode)\n",
    "flatten = Flatten()(inception)\n",
    "logits = Dense(len(classes))(flatten)\n",
    "lrModel = Model(inputNode, logits)\n",
    "classifier = NNClassifier(lrModel, CrossEntropyCriterion(), transformer) \\\n",
    "    .setLearningRate(LEARNING_RATE) \\\n",
    "    .setBatchSize(BATCH_SIZE) \\\n",
    "    .setMaxEpoch(EPOCHS) \\\n",
    "    .setFeaturesCol(\"image\") \\\n",
    "    .setCachingSample(False)\n",
    "pipeline = Pipeline(stages=[classifier])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_model = pipeline.fit(trainingDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingDF.drop()\n",
    "trainingDF = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Flowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validationDF = NNImageReader.readImages('sampled/test/*/*', sc).repartition(32).cache()\n",
    "print (\"partition number: \", validationDF.rdd.getNumPartitions())\n",
    "print (\"image number: \", validationDF.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validationDF = validationDF \\\n",
    "    .withColumn(\"name\", getName(col(\"image\"))) \\\n",
    "    .withColumn(\"label\", getLabel(col('name')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predDF = flower_model.transform(validationDF).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predDF.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = predDF.select(\"name\", \"label\", \"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predDF.unpersist()\n",
    "# predDF.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = results.filter(\"label = prediction\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = predDF.count()\n",
    "accuracy = correct * 1.0 / total\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bigdl.optim.optimizer import Optimizer, Adam, MaxEpoch, EveryEpoch, Top1Accuracy, \\\n",
    "#     TrainSummary, ValidationSummary, SeveralIteration, SGD\n",
    "\n",
    "# from bigdl.nn.layer import Sequential, Linear, LogSoftMax\n",
    "\n",
    "# from bigdl.nn.criterion import ClassNLLCriterion\n",
    "\n",
    "# from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lrModel = Sequential().add(Linear(1000, len(classes))).add(LogSoftMax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier = NNClassifier(lrModel, ClassNLLCriterion(), [1000]) \\\n",
    "#         .setOptimMethod(SGD(nesterov=True, momentum=0.9, dampening=0.0)) \\\n",
    "#         .setLearningRate(LEARNING_RATE) \\\n",
    "#         .setBatchSize(BATCH_SIZE) \\\n",
    "#         .setMaxEpoch(EPOCHS) \\\n",
    "#         .setFeaturesCol(\"embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluator = MulticlassClassificationEvaluator(\n",
    "#     labelCol=\"label\", \n",
    "#     predictionCol=\"prediction\", \n",
    "#     metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline = Pipeline(stages=[transformer, preTrainedNNModel, classifier])\n",
    "# pipeline = Pipeline(stages=[transformer, preTrainedNNModel, classifier])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grocery_model = classifier.fit(trainingEmbedDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainPredictDF = grocery_model.transform(trainingDF)\n",
    "# evaluator.evaluate(trainPredictDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validationEmbedDF = preTrainedNNModel.transform(transformer.transform(validationDF))\n",
    "# predictionDF = grocery_model.transform(validationEmbedDF).cache()\n",
    "# predictionDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluator.evaluate(predictionDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
